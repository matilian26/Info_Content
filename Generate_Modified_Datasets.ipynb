{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "# Section 0\n",
    "\n",
    "# Matplotlib Inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import re # regular expressions\n",
    "import collections\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import subprocess\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Import function file\n",
    "from ic_functions_final import *\n",
    "\n",
    "# Change pd settings to display all dataframe content\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "# Close all pre-existing figures\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "## Section 0: Gene Identifiers Dictionary\n",
    "geneID,NametoIDs,NametoFBid = geneIDdictionary('Datasets/fbgn_annotation_ID_fb_2016_05.tsv')\n",
    "\n",
    "## Section 1: Look at Information Content of TFs\n",
    "\n",
    "# Read PWM data from FlyFactor Survey\n",
    "# PWM,checkFBgn = PWMdictionary(\"Datasets/UmassPGFE_PWMfreq_PublicDatasetA_20150901.txt\")\n",
    "# PWM,checkFBgn = readFASTA(\"Datasets/UmassPGFE_PWMfreq_PublicDatasetA_20150901.txt\", \\\n",
    "#                           re.compile('FBgn\\d*'),'PWM','v',geneID)\n",
    "PWM,checkFBgn,PWMnames = readFASTA('Datasets/UmassPGFE_PWMfreq_PublicDatasetA_20150901.txt', \\\n",
    "                          'PWM','v',geneID,re.compile('(FBgn\\d*)'),pseudocount=0)\n",
    "# Discrepancy Checks:\n",
    "# checkFBgn = 'FBgn0050420', 'FBgn0051782'\n",
    "# 'FBgn0050420': FBgn0050420 associated with CG44246(Atf-2) and CG44247;\n",
    "#                confirmed that protein fragment characterized is in Atf-2: 283-336\n",
    "#                Note that UniProt identifies 281 â€“ 339 as the BZIP\n",
    "# 'FBgn0051782': obsolete protein according to UniProt\n",
    "#                currently references three adjacent genes\n",
    "#                THIS SHOULD BE REMOVED.\n",
    "PWM.pop(geneID['FBgn0051782'][0],None)\n",
    "PWMnames.pop([k for k,v in PWMnames.iteritems() if 'FBgn0051782' in v][0])\n",
    "# Replace da PWM with the da-specific PWM\n",
    "da,checkFBgn_da,PWMnames_da = readFASTA('Datasets/UmassPGFE_PWMfreq_da_SANGER_10_Vertical20160731.txt', \\\n",
    "                          'PWM','v',geneID,re.compile('(FBgn\\d*)'))\n",
    "PWM.update(da)\n",
    "PWMnames.update(PWMnames_da)\n",
    "gt,checkFBgn_gt,PWMnames_gt = readFASTA('Datasets/UmassPGFE_PWMfreq_gt_FlyReg_Vertical20160810.txt', \\\n",
    "                          'PWM','v',geneID,re.compile('(FBgn\\d*)'))\n",
    "PWM.update(gt)\n",
    "PWMnames.update(PWMnames_gt)\n",
    "\n",
    "\n",
    "# First, remove FBgn from the end of the keys because that's how the aligned sequences are\n",
    "# labeled in the file of aligned sequences: UmassPGFE_PWMfreq_PublicDatasetD_20160225.txt\n",
    "filteredPWMnames = {}  # initialize dictionary\n",
    "filteredPWMnamesR = {}\n",
    "regex = re.compile('([\\w\\.\\(\\)-]+)_')\n",
    "for k,v in PWMnames.iteritems():\n",
    "    m = regex.search(v)\n",
    "    filteredPWMnames[k] = m.group(1)\n",
    "    if m.group(1) in filteredPWMnamesR:\n",
    "        filteredPWMnamesR[m.group(1)].append(k)\n",
    "    else:\n",
    "        filteredPWMnamesR[m.group(1)] = [k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No coordinates unlifted.\n",
      "No coordinates unlifted.\n",
      "Done: abd-A\n",
      "Done: Abd-B\n",
      "Done: Adf1\n",
      "Done: Aef1\n",
      "Done: Antp\n",
      "Done: ap\n",
      "[KeyError]: ara is not in PWM_FlyReg\n",
      "[KeyError]: ara is not in PWM_FlyReg\n",
      "Done: bab1\n",
      "[KeyError]: bap is not in PWM_FlyReg\n",
      "Done: bcd\n",
      "[KeyError]: BEAF-32 is not in PWM_FlyReg\n",
      "[KeyError]: BEAF-32 is not in PWM_FlyReg\n",
      "[KeyError]: BEAF-32A is not in PWM_FlyReg\n",
      "[KeyError]: BEAF-32A is not in PWM_FlyReg\n",
      "[KeyError]: BEAF-32B is not in PWM_FlyReg\n",
      "[KeyError]: BEAF-32B is not in PWM_FlyReg\n",
      "Done: bin\n",
      "Done: br-Z1\n",
      "Done: br-Z2\n",
      "Done: br-Z3\n",
      "Done: br-Z4\n",
      "Done: brk\n",
      "Done: byn\n",
      "Done: cad\n",
      "Done: Cf2-II\n",
      "Done: Deaf1\n",
      "Done: Dfd\n",
      "Done: dl\n",
      "[KeyError]: dpn is not in PWM_FlyReg\n",
      "Done: Dref\n",
      "Done: dsx-F\n",
      "Done: dsx-M\n",
      "[KeyError]: dwg is not in PWM_FlyReg\n",
      "Done: E(spl)\n",
      "Done: Eip74EF\n",
      "Done: ems\n",
      "Done: en\n",
      "Done: eve\n",
      "Done: exd\n",
      "Done: ey\n",
      "[KeyError]: fkh is not in PWM_FlyReg\n",
      "Done: ftz\n",
      "Done: ftz-f1\n",
      "Done: gl\n",
      "Done: grh\n",
      "[KeyError]: gsb is not in PWM_FlyReg\n",
      "[KeyError]: gsb is not in PWM_FlyReg\n",
      "[KeyError]: gsb-n is not in PWM_FlyReg\n",
      "[KeyError]: gsb-n is not in PWM_FlyReg\n",
      "Done: gt\n",
      "Done: hb\n",
      "[KeyError]: His2B is not in PWM_FlyReg\n",
      "[KeyError]: His2B is not in PWM_FlyReg\n",
      "[KeyError]: His2B is not in PWM_FlyReg\n",
      "[KeyError]: His2B is not in PWM_FlyReg\n",
      "[KeyError]: His2B is not in PWM_FlyReg\n",
      "[KeyError]: hkb is not in PWM_FlyReg\n",
      "[KeyError]: hkb is not in PWM_FlyReg\n",
      "Done: HLHm5\n",
      "[KeyError]: Hr39 is not in PWM_FlyReg\n",
      "Done: Hr46\n",
      "Done: Hsf\n",
      "Done: kni\n",
      "Done: Kr\n",
      "Done: Mad\n",
      "Done: Med\n",
      "[KeyError]: Myb is not in PWM_FlyReg\n",
      "Done: nub\n",
      "Done: ovo\n",
      "[KeyError]: p120 is not in PWM_FlyReg\n",
      "[KeyError]: p120 is not in PWM_FlyReg\n",
      "[KeyError]: p120 is not in PWM_FlyReg\n",
      "Done: pan\n",
      "Done: pho\n",
      "Done: prd\n",
      "Done: sd\n",
      "[KeyError]: shn is not in PWM_FlyReg\n",
      "[KeyError]: shn is not in PWM_FlyReg\n",
      "Done: slbo\n",
      "[KeyError]: slp1 is not in PWM_FlyReg\n",
      "Done: sna\n",
      "[KeyError]: so is not in PWM_FlyReg\n",
      "Done: srp\n",
      "Done: Su(H)\n",
      "Done: su(Hw)\n",
      "Done: tin\n",
      "Done: tll\n",
      "[KeyError]: Top2 is not in PWM_FlyReg\n",
      "[KeyError]: Top2 is not in PWM_FlyReg\n",
      "[KeyError]: Top2 is not in PWM_FlyReg\n",
      "[KeyError]: Top2 is not in PWM_FlyReg\n",
      "Done: toy\n",
      "[KeyError]: Trf is not in PWM_FlyReg\n",
      "Done: Trl\n",
      "Done: ttk\n",
      "Done: twi\n",
      "Done: Ubx\n",
      "[KeyError]: usp is not in PWM_FlyReg\n",
      "Done: vnd\n",
      "Done: vvl\n",
      "Done: z\n",
      "Done: zen\n",
      "[KeyError]: zfh1 is not in PWM_FlyReg\n",
      "abd-A: 41 aligned sequences/37 in PWM\n",
      "ap: 14 aligned sequences/12 in PWM\n",
      "bcd: 48 aligned sequences/48 in PWM\n",
      "br-Z2: 22 aligned sequences/21 in PWM\n",
      "Dref: 9 aligned sequences/8 in PWM\n",
      "en: 56 aligned sequences/53 in PWM\n",
      "eve: 20 aligned sequences/19 in PWM\n",
      "ftz: 66 aligned sequences/66 in PWM\n",
      "grh: 9 aligned sequences/8 in PWM\n",
      "hb: 103 aligned sequences/103 in PWM\n",
      "kni: 33 aligned sequences/20 in PWM\n",
      "Kr: 45 aligned sequences/44 in PWM\n",
      "Mad: 19 aligned sequences/20 in PWM\n",
      "**Mad is missing 1 aligned sequences.**\n",
      "sd: 19 aligned sequences/14 in PWM\n",
      "tll: 37 aligned sequences/37 in PWM\n",
      "Trl: 77 aligned sequences/71 in PWM\n",
      "ttk: 8 aligned sequences/7 in PWM\n",
      "Ubx: 60 aligned sequences/56 in PWM\n",
      "abd-A\n",
      "['abd-A_1', 'abd-A_10', 'abd-A_11', 'abd-A_12', 'abd-A_13', 'abd-A_14', 'abd-A_15', 'abd-A_16', 'abd-A_17', 'abd-A_18', 'abd-A_19', 'abd-A_2', 'abd-A_20', 'abd-A_21', 'abd-A_22', 'abd-A_23', 'abd-A_24', 'abd-A_25', 'abd-A_26', 'abd-A_27', 'abd-A_28', 'abd-A_3', 'abd-A_30', 'abd-A_31', 'abd-A_32', 'abd-A_33', 'abd-A_34', 'abd-A_35', 'abd-A_36', 'abd-A_37', 'abd-A_38', 'abd-A_39', 'abd-A_40', 'abd-A_41', 'abd-A_5', 'abd-A_6', 'abd-A_9']\n",
      "ap\n",
      "['ap_1', 'ap_10', 'ap_12', 'ap_14', 'ap_2', 'ap_3', 'ap_4', 'ap_5', 'ap_6', 'ap_7', 'ap_8', 'ap_9']\n",
      "br-Z2\n",
      "['br-Z2_1', 'br-Z2_10', 'br-Z2_11', 'br-Z2_12', 'br-Z2_13', 'br-Z2_14', 'br-Z2_15', 'br-Z2_16', 'br-Z2_17', 'br-Z2_18', 'br-Z2_18_2', 'br-Z2_19', 'br-Z2_2', 'br-Z2_20', 'br-Z2_21', 'br-Z2_4', 'br-Z2_5', 'br-Z2_6', 'br-Z2_7', 'br-Z2_8', 'br-Z2_9']\n",
      "['br-Z2_1', 'br-Z2_10', 'br-Z2_11', 'br-Z2_12', 'br-Z2_13', 'br-Z2_14', 'br-Z2_15', 'br-Z2_16', 'br-Z2_17', 'br-Z2_18_2', 'br-Z2_19', 'br-Z2_2', 'br-Z2_20', 'br-Z2_21', 'br-Z2_3', 'br-Z2_4', 'br-Z2_5', 'br-Z2_6', 'br-Z2_7', 'br-Z2_8', 'br-Z2_9']\n",
      "Dref\n",
      "['Dref_1', 'Dref_3', 'Dref_4', 'Dref_5', 'Dref_6', 'Dref_7', 'Dref_8', 'Dref_9']\n",
      "eve\n",
      "['eve_1', 'eve_10', 'eve_12', 'eve_13', 'eve_14', 'eve_15', 'eve_16', 'eve_17', 'eve_18', 'eve_19', 'eve_2', 'eve_20', 'eve_3', 'eve_4', 'eve_5', 'eve_6', 'eve_7', 'eve_8', 'eve_9']\n",
      "grh\n",
      "['grh_2', 'grh_3', 'grh_4', 'grh_5', 'grh_6', 'grh_7', 'grh_8', 'grh_9']\n",
      "Kr\n",
      "['Kr_1', 'Kr_10', 'Kr_11', 'Kr_12', 'Kr_13', 'Kr_14', 'Kr_15', 'Kr_16', 'Kr_17', 'Kr_18', 'Kr_19', 'Kr_2', 'Kr_20', 'Kr_21', 'Kr_22', 'Kr_23', 'Kr_24', 'Kr_25', 'Kr_26', 'Kr_27', 'Kr_29', 'Kr_3', 'Kr_30', 'Kr_31', 'Kr_32', 'Kr_33', 'Kr_34', 'Kr_35', 'Kr_36', 'Kr_37', 'Kr_38', 'Kr_39', 'Kr_4', 'Kr_40', 'Kr_41', 'Kr_42', 'Kr_43', 'Kr_44', 'Kr_45', 'Kr_5', 'Kr_6', 'Kr_7', 'Kr_8', 'Kr_9']\n",
      "ttk\n",
      "['ttk_1', 'ttk_2', 'ttk_3', 'ttk_4', 'ttk_5', 'ttk_6', 'ttk_7']\n"
     ]
    }
   ],
   "source": [
    "# ONLY NEEDS TO BE RUN ONCE\n",
    "\n",
    "# Section 2: Determine and write aligned FlyReg sequences to the aligned sequence files\n",
    "# Read in the footprints for the TFs that only have PWMs based on FlyReg footprints: brk, Mad, Med\n",
    "regex = re.compile('(\\w+)\\tBergman_data\\tbinding_site\\t(\\d+)\\t(\\d+)\\t\\.\\t\\.\\t\\.\\tFactor\\s([\\w\\\"\\-\\(\\)\\.]+)')\n",
    "# group(1) = chromosome\n",
    "# group(2) = start\n",
    "# group(3) = end\n",
    "# group(4) = TF\n",
    "\n",
    "if not os.path.exists('Datasets/Modified'):\n",
    "    os.makedirs('Datasets/Modified')\n",
    "\n",
    "FlyRegTFs = []\n",
    "with open('Datasets/Modified/FlyRegTFs.bed','w') as f:\n",
    "    with open('Datasets/Footprint.GFF','r') as f1:\n",
    "        for line in f1:\n",
    "            m = regex.search(line)\n",
    "            if m:\n",
    "                if m.group(4)[1:-1] not in FlyRegTFs:\n",
    "                    FlyRegTFs.append(m.group(4)[1:-1])\n",
    "                f.write('chr%s\\t%s\\t%s\\t%s\\n' %(m.group(1),m.group(2),m.group(3),m.group(4)[1:-1]))\n",
    "FlyRegTFs = sorted(FlyRegTFs, key=lambda t:t.lower())\n",
    "\n",
    "# Liftover from dm2 (Release 4) to dm6\n",
    "command = []\n",
    "# Liftover from dm2 to dm3\n",
    "command.append(['./liftOver', \\\n",
    "                'Datasets/Modified/FlyRegTFs.bed', \\\n",
    "                'Datasets/dm2ToDm3.over.chain.gz', \\\n",
    "                'Datasets/Modified/FlyRegTFs_dm3.bed', \\\n",
    "                'Datasets/Modified/FlyRegTFs_unlifted.bed'])\n",
    "# Liftover from dm3 to dm6\n",
    "command.append(['./liftOver', \\\n",
    "                'Datasets/Modified/FlyRegTFs_dm3.bed', \\\n",
    "                'Datasets/dm3ToDm6.over.chain.gz', \\\n",
    "                'Datasets/Modified/FlyRegTFs_dm6.bed', \\\n",
    "                'Datasets/Modified/FlyRegTFs_unlifted.bed'])\n",
    "for cmd in command:\n",
    "    process = subprocess.call(cmd)\n",
    "    # Sanity check: no coordinates unlifted\n",
    "    if os.stat('Datasets/Modified/FlyRegTFs_unlifted.bed').st_size == 0:\n",
    "        print 'No coordinates unlifted.'\n",
    "    else:\n",
    "        print 'Some coordinates unlifted!'\n",
    "\n",
    "# Pick out the sequences from dm6 and run patser on them\n",
    "# Remove 'Unspecified' because those sequences don't pertain to the PWM of any TF\n",
    "if 'Unspecified' in FlyRegTFs:\n",
    "    FlyRegTFs.remove('Unspecified')\n",
    "# For names from the Fly Reg footprint database that don't match with those from the FlyReg PWM database, \n",
    "# provide translation dictionary\n",
    "translations = dict(zip(['abd-A','E(spl)','Su(H)','su(Hw)'],['Abd-A','Espl','SuH','suHw']))\n",
    "temp = list(set(FlyRegTFs)-set(translations.keys()))\n",
    "translations.update(dict(zip(temp,temp)))\n",
    "# For names from the Fly Reg footprint database with the gene symbol designated in Flybase/PWM database, \n",
    "# provide translation dictionary\n",
    "keys = sorted([TF for TF in FlyRegTFs if TF not in PWM.keys()], key=lambda t: t.lower())\n",
    "values = ['BEAF-32','BEAF-32','BEAF-32','br','br','br','br','Cf2','dsx','dsx','dwg','E(spl)m8-HLH','His2B','E(spl)m5-HLH','Myb','p120','Top2','Trf','zfh1']\n",
    "translations1 = dict(zip(keys,values))\n",
    "temp = list(set(FlyRegTFs)-set(keys))\n",
    "translations1.update(dict(zip(temp,temp)))\n",
    "# Save the raw sequences for later use\n",
    "Raw_Seq = {}\n",
    "# Pull out the FlyReg PWMs (pseudocount = 0)\n",
    "PWM_FlyReg,checkFBgn_FlyReg,PWMnames_FlyReg = readFASTA('Datasets/UmassPGFE_PWMfreq_PublicDatasetA_20150901.txt', \\\n",
    "                                                'PWM','v',geneID,re.compile('([\\w\\-\\.\\(\\)]+)_FlyReg_FBgn\\d*'),nameasis=1,pseudocount=0)\n",
    "# Write the FlyReg PWMs to file to be used with patser\n",
    "### make the matrix files for PATSER\n",
    "bases = ['A','C','G','T']\n",
    "for key in PWM_FlyReg:\n",
    "    if not os.path.exists('matrix/FlyReg'):\n",
    "        os.makedirs('matrix/FlyReg')\n",
    "    with open('matrix/FlyReg/%s.txt' %key, 'w') as f:       \n",
    "        with open('matrix/FlyReg/%s.txt' %key, 'a') as f:\n",
    "            for i in range(0,4): #for each base\n",
    "                temp = ['%s |' %bases[i]] + \\\n",
    "                       map(str,np.transpose(PWM_FlyReg[key])[i,:].tolist())\n",
    "                temp1 = ''.join([x+'\\t' for x in temp]) + '\\n'\n",
    "                f.write(temp1)\n",
    "\n",
    "# Read in the dm6 genome\n",
    "dm6 = readFASTA('Datasets/dm6.fa',0,'sequences',0,0,0)\n",
    "# Create directories for raw sequences and patser-processed raw sequences\n",
    "directories = ['patserIn/RawSeq', \\\n",
    "               'patserOut/RawSeq']\n",
    "for d in directories:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "# path to patser\n",
    "path_to_patser = 'patser-v3e.1/patser-v3e'\n",
    "# 1) Read in the raw sequences, 2) write to TF-specific raw sequence files, and 3) run patser\n",
    "for TF in FlyRegTFs:\n",
    "    ctr = 0 # counter for the sequence\n",
    "    with open('patserIn/RawSeq/RawSeq_%s.txt' %TF,'w') as f1:\n",
    "        with open('Datasets/Modified/FlyRegTFs_dm6.bed','r') as f:\n",
    "            for line in f:\n",
    "                temp = line.strip().split('\\t')\n",
    "                # temp[0] = chromosome\n",
    "                # temp[1] = start\n",
    "                # temp[2] = end\n",
    "                # temp[3] = TF name\n",
    "                if temp[3] == TF:\n",
    "                    ctr +=1\n",
    "                    try:\n",
    "                        # if the raw sequence is shorter than the PWM, add +/- 10bp to the raw sequence\n",
    "                        if int(temp[2])-int(temp[1])+1 < PWM_FlyReg[translations[TF]].shape[0]:\n",
    "                            f1.write('%s_%s \\ %s \\ \\n' %(temp[3],ctr, dm6[temp[0]][int(temp[1])-11:int(temp[2])+10]))\n",
    "                            Raw_Seq['%s_%s' %(temp[3],ctr)] = dm6[temp[0]][int(temp[1])-11:int(temp[2])+10]\n",
    "                        else: # write raw sequence as is\n",
    "                            f1.write('%s_%s \\ %s \\ \\n' %(temp[3],ctr, dm6[temp[0]][int(temp[1])-1:int(temp[2])]))\n",
    "                            Raw_Seq['%s_%s' %(temp[3],ctr)] = dm6[temp[0]][int(temp[1])-1:int(temp[2])]\n",
    "                    except KeyError: # if no PWM exists for these sequences, write raw sequences to file as is\n",
    "                        print '[KeyError]: %s is not in PWM_FlyReg' %TF\n",
    "                        f1.write('%s_%s \\ %s \\ \\n' %(temp[3],ctr, dm6[temp[0]][int(temp[1])-1:int(temp[2])]))\n",
    "                        Raw_Seq['%s_%s' %(temp[3],ctr)] = dm6[temp[0]][int(temp[1])-1:int(temp[2])]\n",
    "\n",
    "    # run Patser using FlyReg PWMs\n",
    "    if translations[TF] in PWM_FlyReg.keys():\n",
    "        matrix = 'matrix/FlyReg/%s.txt' %translations[TF] # path to FlyReg TF PWM file\n",
    "        inputFile = 'patserIn/RawSeq/RawSeq_%s.txt' %TF # input sequences\n",
    "        outputFile = 'patserOut/RawSeq/RawSeq_%s.txt' %TF # PATSER output\n",
    "\n",
    "        cmd = [path_to_patser, '-A', 'a:t', '0.297', 'c:g', '0.203', \\\n",
    "               '-p', '-m', matrix, '-b', '0.01', '-c', '-d1', '-t', '-f', inputFile] \n",
    "\n",
    "        process = subprocess.call(cmd,stdout = open(outputFile, 'w'))\n",
    "        print('Done: %s' %TF)\n",
    "\n",
    "# First pass at using patser results to determine aligned sequences\n",
    "AlignedSeq_FlyReg = {} # dictionary of aligned sequences (in case there are repeats)\n",
    "mismatch_AlignedSeq = [] # list of PWMs for which some raw sequences have not been used, i.e. n_raw seq > n_aligned seq\n",
    "missing_AlignedSeq = [] # list of PWMs for which some aligned sequences are missing\n",
    "temp_PWM_FlyReg = {} # dictionary of PWMs created from aligned sequences\n",
    "RC = {'A':'T','T':'A','C':'G','G':'C'} # reverse complement dictionary\n",
    "index = {'A':0,'C':1,'G':2,'T':3}\n",
    "regex = re.compile('([\\w\\-\\.\\(\\)]+)\\s+position=\\s+([\\dC]+)')\n",
    "# group(1) = enhancer, or sequence name\n",
    "# group(2) = position\n",
    "for TF in FlyRegTFs:\n",
    "    PWM_TF = translations[TF]\n",
    "    if PWM_TF in PWM_FlyReg.keys(): # if a FlyReg PWM exists for this TF\n",
    "        AlignedSeq_FlyReg[TF] = {} # initialize FlyReg aligned sequence dictionary for TF\n",
    "        ctr = 0 # counter for saved sequences\n",
    "        temp_PWM = np.zeros((PWM_FlyReg[PWM_TF].shape)) # initialize PWM created with these aligned sequences\n",
    "        with open('patserOut/RawSeq/RawSeq_%s.txt' %TF,'r') as f:\n",
    "            for line in f:\n",
    "                m = regex.search(line)\n",
    "                if m:\n",
    "                    save = 0\n",
    "                    if 'C' in m.group(2):\n",
    "                        i = int(m.group(2)[:-1]) # position in the sequence\n",
    "                        temp_seq = ''.join([RC[base.upper()] for base in Raw_Seq[m.group(1)]])[i-1:i-1+PWM_FlyReg[PWM_TF].shape[0]][::-1].upper()\n",
    "                        if m.group(1) not in AlignedSeq_FlyReg[TF].keys():\n",
    "                            ctr1,save = 1,1 # counter for raw sequence, use this sequence in PWM\n",
    "                            AlignedSeq_FlyReg[TF].update({m.group(1):temp_seq})\n",
    "                            ctr += 1 # increment counter of all saved sequences\n",
    "                        elif (m.group(1) in AlignedSeq_FlyReg[TF].keys() and temp_seq not in [seq for tf,seq in AlignedSeq_FlyReg[TF].iteritems() if m.group(1) in tf]):\n",
    "                            ctr1 += 1 # counter for raw sequence incremented if same sequence has more than one alignment\n",
    "                            save = 1\n",
    "                            AlignedSeq_FlyReg[TF].update({'%s_%d' %(m.group(1),ctr1):temp_seq})\n",
    "                            ctr += 1\n",
    "                    else:\n",
    "                        i = int(m.group(2)) # position in the sequence\n",
    "                        temp_seq = Raw_Seq[m.group(1)][i-1:i-1+PWM_FlyReg[PWM_TF].shape[0]].upper()\n",
    "                        if m.group(1) not in AlignedSeq_FlyReg[TF].keys():\n",
    "                            ctr1,save = 1,1\n",
    "                            AlignedSeq_FlyReg[TF].update({m.group(1):temp_seq})\n",
    "                            ctr += 1\n",
    "                        elif (m.group(1) in AlignedSeq_FlyReg[TF].keys() and temp_seq not in [seq for tf,seq in AlignedSeq_FlyReg[TF].iteritems() if m.group(1) in tf]):#AlignedSeq_FlyReg[TF][m.group(1)] != temp_seq):\n",
    "                            ctr1 += 1\n",
    "                            save = 1\n",
    "                            AlignedSeq_FlyReg[TF].update({'%s_%d' %(m.group(1),ctr1):temp_seq})\n",
    "                            ctr += 1\n",
    "                    if save == 1: # if aligned sequence is unique or raw seq produced multiple alignments\n",
    "                        for position,base in enumerate(temp_seq):\n",
    "                            temp_PWM[position,index[base]] += 1\n",
    "\n",
    "        temp_PWM_FlyReg[PWM_TF] = temp_PWM\n",
    "        if not np.array_equal(temp_PWM,PWM_FlyReg[PWM_TF]):\n",
    "            mismatch_AlignedSeq.append(TF)\n",
    "            print '%s: %d aligned sequences/%d in PWM' %(TF,ctr,math.floor(sum(PWM_FlyReg[PWM_TF][0]))) \n",
    "        if ctr < math.floor(sum(PWM_FlyReg[translations[TF]][0])):\n",
    "            missing_AlignedSeq.append(TF)\n",
    "            print '**%s is missing %d aligned sequences.**' %(TF,math.floor(sum(PWM_FlyReg[PWM_TF][0]))-ctr)  \n",
    "\n",
    "# For those PWMs that don't use all the raw sequences, determine which combination produces the PWM\n",
    "subsets = {}\n",
    "# for TF in AlignedSeq_FlyReg.keys():\n",
    "for TF in ['abd-A','ap','br-Z2','Dref','eve','grh','Kr','ttk']:\n",
    "# for TF in ['abd-A']:\n",
    "    timeout = time.time() + 60\n",
    "    if len(AlignedSeq_FlyReg[TF]) != int(math.floor(sum(PWM_FlyReg[translations[TF]][0]))):\n",
    "        print TF\n",
    "        for subset in itertools.combinations(AlignedSeq_FlyReg[TF].keys(), int(math.floor(sum(PWM_FlyReg[translations[TF]][0])))):\n",
    "            temp_PWM = np.zeros((PWM_FlyReg[translations[TF]].shape))\n",
    "            for seq in subset:\n",
    "                for position,base in enumerate(AlignedSeq_FlyReg[TF][seq]):\n",
    "                    temp_PWM[position,index[base]] += 1\n",
    "            if np.array_equal(temp_PWM,PWM_FlyReg[translations[TF]]):\n",
    "                if TF in subsets.keys():\n",
    "                    subsets[TF].append([subset])\n",
    "                else:\n",
    "                    subsets[TF] = [subset]\n",
    "                temp_PWM_FlyReg[translations[TF]] = temp_PWM\n",
    "                print sorted(subset)\n",
    "            if time.time() > timeout:\n",
    "                break\n",
    "        if TF != 'br-Z2':\n",
    "            AlignedSeq_FlyReg[TF] = {k:v for k,v in AlignedSeq_FlyReg[TF].iteritems() if k in subsets[TF][0]}\n",
    "        else:\n",
    "            AlignedSeq_FlyReg[TF] = {k:v for k,v in AlignedSeq_FlyReg[TF].iteritems() if k in subsets[TF][1]}\n",
    "\n",
    "# Add the missing sequence for the Mad PWM\n",
    "temp = PWM['Mad']-temp_PWM_FlyReg['Mad']\n",
    "indexRev = {v:k for k,v in index.iteritems()}\n",
    "AlignedSeq_FlyReg['Mad']['Mad_20'] = ''.join(indexRev[[idx for idx, val in enumerate(temp[i]) if val >= 1][0]] for i in range(len(PWM['Mad'])))\n",
    "            \n",
    "# Create patserIn/AlignedSeq if it does not exist\n",
    "if not os.path.exists('patserIn/AlignedSeq'):\n",
    "    os.makedirs('patserIn/AlignedSeq')\n",
    "\n",
    "translationsRev = {v:k for k,v in translations1.iteritems()}\n",
    "# filteredPWMnamesRev = {v:k for k,v in filteredPWMnames.iteritems()}\n",
    "od_AlignedSeq_FlyReg = {TF:collections.OrderedDict([(k,seq[k]) for k in sorted(seq,key=lambda string: [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string)])]) for TF,seq in AlignedSeq_FlyReg.iteritems()}\n",
    "# for the FlyReg PWMs in PWM dictionary minus those whose raw sequences I was unable to align\n",
    "for TF in list(set([k for k,v in PWMnames.iteritems() if 'FlyReg' in v])-(set(mismatch_AlignedSeq)-set(['Mad'])-set(subsets.keys()))):\n",
    "    ctr = 1\n",
    "    FlyReg_TF = translationsRev[TF]\n",
    "    with open('patserIn/AlignedSeq/%s.txt' %TF,'w') as f:\n",
    "        for seq in od_AlignedSeq_FlyReg[FlyReg_TF].values():\n",
    "            f.write('%s_%d \\ %s \\ \\n' %(filteredPWMnames[TF],ctr,seq))\n",
    "            ctr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ab\n",
      "Done: abd-A\n",
      "Done: Abd-B\n",
      "Done: ac\n",
      "Done: achi\n",
      "Done: acj6\n",
      "Done: Adf1\n",
      "Done: Aef1\n",
      "Done: al\n",
      "Done: amos\n",
      "Done: Antp\n",
      "Done: aop\n",
      "Done: ap\n",
      "Done: ara\n",
      "Done: Asciz\n",
      "Done: ase\n",
      "Done: Atf-2\n",
      "Done: Atf6\n",
      "Done: ato\n",
      "Done: Awh\n",
      "Done: B-H1\n",
      "Done: B-H2\n",
      "Done: bab1\n",
      "Done: bap\n",
      "Done: bcd\n",
      "Done: Bgb\n",
      "Done: bigmax\n",
      "Done: bin\n",
      "Done: Blimp-1\n",
      "Done: bowl\n",
      "Done: br\n",
      "Done: brk\n",
      "Done: bsh\n",
      "Done: BtbVII\n",
      "Done: btd\n",
      "Done: btn\n",
      "Done: byn\n",
      "Done: C15\n",
      "Done: cad\n",
      "Done: cato\n",
      "Done: caup\n",
      "Done: Cf2\n",
      "Done: CG10904\n",
      "Done: CG11085\n",
      "Done: CG11294\n",
      "Done: CG11504\n",
      "Done: CG11617\n",
      "Done: CG12155\n",
      "Done: CG12236\n",
      "Done: CG12605\n",
      "Done: CG12768\n",
      "Done: CG15601\n",
      "Done: CG15696\n",
      "Done: CG15812\n",
      "Done: CG18599\n",
      "Done: CG3065\n",
      "Done: CG32532\n",
      "Done: CG33557\n",
      "Done: CG34031\n",
      "Done: CG3407\n",
      "Done: CG3838\n",
      "Done: CG3919\n",
      "Done: CG42741\n",
      "Done: CG4328\n",
      "Done: CG4360\n",
      "Done: CG4404\n",
      "Done: CG4854\n",
      "Done: CG5180\n",
      "Done: CG5953\n",
      "Done: CG6272\n",
      "Done: CG6276\n",
      "Done: CG7368\n",
      "Done: CG7745\n",
      "Done: CG8281\n",
      "Done: CG8319\n",
      "Done: CG8765\n",
      "Done: CG9876\n",
      "Done: chinmo\n",
      "Done: ci\n",
      "Done: cic\n",
      "Done: Clk\n",
      "Done: Coop\n",
      "Done: crc\n",
      "Done: CrebA\n",
      "Done: crol\n",
      "Done: crp\n",
      "Done: ct\n",
      "Done: cwo\n",
      "Done: cyc\n",
      "Done: D\n",
      "Done: D19A\n",
      "Done: D19B\n",
      "Done: da\n",
      "Done: dar1\n",
      "Done: dati\n",
      "Done: Dbx\n",
      "Done: Deaf1\n",
      "Done: Dfd\n",
      "Done: dimm\n",
      "Done: disco-r\n",
      "Done: disco\n",
      "Done: dl\n",
      "Done: Dlip3\n",
      "Done: Dll\n",
      "Done: Doc2\n",
      "Done: dpn\n",
      "Done: Dr\n",
      "Done: Dref\n",
      "Done: dsf\n",
      "Done: dsx\n",
      "Done: dysf\n",
      "Done: E(spl)m3-HLH\n",
      "Done: E(spl)m5-HLH\n",
      "Done: E(spl)m7-HLH\n",
      "Done: E(spl)m8-HLH\n",
      "Done: E(spl)mbeta-HLH\n",
      "Done: E(spl)mdelta-HLH\n",
      "Done: E(spl)mgamma-HLH\n",
      "Done: E5\n",
      "Done: EcR\n",
      "Done: eg\n",
      "Done: Eip74EF\n",
      "Done: Eip75B\n",
      "Done: Eip78C\n",
      "Done: Eip93F\n",
      "Done: ems\n",
      "Done: en\n",
      "Done: erm\n",
      "Done: ERR\n",
      "Done: esg\n",
      "Done: Ets21C\n",
      "Done: Ets65A\n",
      "Done: Ets96B\n",
      "Done: Ets97D\n",
      "Done: Ets98B\n",
      "Done: eve\n",
      "Done: exd\n",
      "Done: exex\n",
      "Done: ey\n",
      "Done: fd64A\n",
      "Done: Fer1\n",
      "Done: Fer2\n",
      "Done: Fer3\n",
      "Done: fkh\n",
      "Done: foxo\n",
      "Done: FoxP\n",
      "Done: fru\n",
      "Done: ftz-f1\n",
      "Done: ftz\n",
      "Done: GATAd\n",
      "Done: GATAe\n",
      "Done: gce\n",
      "Done: gl\n",
      "Done: grh\n",
      "Done: gsb-n\n",
      "Done: gsb\n",
      "Done: Gsc\n",
      "Done: gt\n",
      "Done: h\n",
      "Done: H2.0\n",
      "Done: Hand\n",
      "Done: hb\n",
      "Done: hbn\n",
      "Done: her\n",
      "Done: Hesr\n",
      "Done: Hey\n",
      "Done: HGTX\n",
      "Done: HHEX\n",
      "Done: hkb\n",
      "Done: HLH4C\n",
      "Done: HLH54F\n",
      "Done: Hmx\n",
      "Done: Hnf4\n",
      "Done: hng1\n",
      "Done: hng3\n",
      "Done: Hr3\n",
      "Done: Hr39\n",
      "Done: Hr4\n",
      "Done: Hr51\n",
      "Done: Hr78\n",
      "Done: Hr83\n",
      "Done: Hsf\n",
      "Done: hth\n",
      "Done: ind\n",
      "Done: inv\n",
      "Done: jigr1\n",
      "Done: jim\n",
      "Done: Jra\n",
      "Done: Kah\n",
      "Done: kay\n",
      "Done: ken\n",
      "Done: Klf15\n",
      "Done: klu\n",
      "Done: kni\n",
      "Done: knrl\n",
      "Done: Kr\n",
      "Done: l(1)sc\n",
      "Done: l(3)neo38\n",
      "Done: lab\n",
      "Done: lbe\n",
      "Done: lbl\n",
      "Done: Lim1\n",
      "Done: Lim3\n",
      "Done: lmd\n",
      "Done: lms\n",
      "Done: Lmx1a\n",
      "Done: lola\n",
      "Done: lov\n",
      "Done: luna\n",
      "Done: Mad\n",
      "Done: mamo\n",
      "Done: Max\n",
      "Done: Med\n",
      "Done: Mes2\n",
      "Done: Met\n",
      "Done: mirr\n",
      "Done: Mitf\n",
      "Done: Mnt\n",
      "Done: Mondo\n",
      "Done: Myc\n",
      "Done: nau\n",
      "Done: net\n",
      "Done: NFAT\n",
      "Done: NK7.1\n",
      "Done: nub\n",
      "Done: oc\n",
      "Done: odd\n",
      "Done: OdsH\n",
      "Done: Oli\n",
      "Done: onecut\n",
      "Done: opa\n",
      "Done: Optix\n",
      "Done: otp\n",
      "Done: ovo\n",
      "Done: pad\n",
      "Done: pan\n",
      "Done: pb\n",
      "Done: pdm2\n",
      "Done: pdm3\n",
      "Done: peb\n",
      "Done: PHDP\n",
      "Done: pho\n",
      "Done: phol\n",
      "Done: pnr\n",
      "Done: pnt\n",
      "Done: Poxm\n",
      "Done: Poxn\n",
      "Done: Pph13\n",
      "Done: prd\n",
      "Done: Ptx1\n",
      "Done: Rel\n",
      "Done: repo\n",
      "Done: retn\n",
      "Done: rib\n",
      "Done: rn\n",
      "Done: ro\n",
      "Done: run\n",
      "Done: Rx\n",
      "Done: sage\n",
      "Done: salr\n",
      "Done: sc\n",
      "Done: schlank\n",
      "Done: Scr\n",
      "Done: scrt\n",
      "Done: sens-2\n",
      "Done: sens\n",
      "Done: shn\n",
      "Done: Sidpn\n",
      "Done: sim\n",
      "Done: sima\n",
      "Done: Six4\n",
      "Done: slbo\n",
      "Done: slou\n",
      "Done: slp1\n",
      "Done: slp2\n",
      "Done: sna\n",
      "Done: so\n",
      "Done: sob\n",
      "Done: Sox14\n",
      "Done: Sox15\n",
      "Done: Sp1\n",
      "Done: Spps\n",
      "Done: sqz\n",
      "Done: sr\n",
      "Done: SREBP\n",
      "Done: srp\n",
      "Done: ss\n",
      "Done: Su(H)\n",
      "Done: su(Hw)\n",
      "Done: sug\n",
      "Done: sv\n",
      "Done: svp\n",
      "Done: tai\n",
      "Done: tap\n",
      "Done: tgo\n",
      "Done: tin\n",
      "Done: tj\n",
      "Done: tll\n",
      "Done: toy\n",
      "Done: ttk\n",
      "Done: tup\n",
      "Done: twi\n",
      "Done: tx\n",
      "Done: Ubx\n",
      "Done: unc-4\n",
      "Done: unpg\n",
      "Done: Usf\n",
      "Done: usp\n",
      "Done: vis\n",
      "Done: vnd\n",
      "Done: vri\n",
      "Done: Vsx1\n",
      "Done: Vsx2\n",
      "Done: vvl\n",
      "Done: wor\n",
      "Done: Xrp1\n",
      "Done: z\n",
      "Done: zen\n",
      "Done: zen2\n",
      "Done: Zif\n",
      "Done: ZIPIC\n",
      "Done: zld\n"
     ]
    }
   ],
   "source": [
    "# ONLY NEEDS TO DONE ONCE\n",
    "# Section 3: Write aligned sequences to file and determine ln(p-value) distributions of aligned sequences\n",
    "\n",
    "# remove patserIn/AlignedSeq directory if it exists\n",
    "if os.path.exists('matrix'):\n",
    "    shutil.rmtree('matrix')\n",
    "\n",
    "## make the matrix files for PATSER\n",
    "bases = ['A','C','G','T']\n",
    "for key in PWM:\n",
    "#    gene = FBidtoName[key]\n",
    "    if not os.path.exists('matrix'):\n",
    "        os.makedirs('matrix')\n",
    "    with open('matrix/%s.txt' %key, 'w') as f:       \n",
    "        with open('matrix/%s.txt' %key, 'a') as f:\n",
    "            for i in range(0,4): #for each base\n",
    "                temp = ['%s |' %bases[i]] + \\\n",
    "                       map(str,np.transpose(PWM[key])[i,:].tolist())\n",
    "                temp1 = ''.join([x+'\\t' for x in temp]) + '\\n'\n",
    "                f.write(temp1)\n",
    "\n",
    "### Calculate the ln(p-values) of all aligned sequences used to produce the PWMs\n",
    "\n",
    "# Write aligned sequences associated with PWMs to file\n",
    "AlignedSeq = {} # dictionary aligned sequences\n",
    "hasAlignedSeq = [] # list of TFs that have aligned sequences\n",
    "TF_fullname = []\n",
    "regex = re.compile('([\\w\\.\\(\\)-]+)\\s>>_?([\\w\\.\\(\\)-]+)') #\n",
    "regex1 = re.compile('^[ACTG]{2,}$')\n",
    "\n",
    "with open('Datasets/UmassPGFE_PWMfreq_PublicDatasetD_20160225.txt') as f:\n",
    "    for line in f:\n",
    "        m = regex.search(line)\n",
    "        if m:\n",
    "            TF_fullname.append(m.group(1)) # full name\n",
    "            ctr = 1\n",
    "            if TF_fullname[-1] in filteredPWMnamesR.keys():\n",
    "                for TF in filteredPWMnamesR[TF_fullname[-1]]:\n",
    "                    try:\n",
    "                        os.remove('patserIn/AlignedSeq/%s.txt' %TF)\n",
    "                    except:\n",
    "                        pass\n",
    "        if regex1.search(line):\n",
    "            if TF_fullname[-1] in filteredPWMnamesR.keys():\n",
    "                AlignedSeq['%s_%s' %(TF_fullname[-1],ctr)] = line[:-1]\n",
    "                for TF in filteredPWMnamesR[TF_fullname[-1]]:\n",
    "                    with open('patserIn/AlignedSeq/%s.txt' %TF, 'a+') as f1:\n",
    "                            f1.write('%s_%s \\ %s \\ \\n' %(TF_fullname[-1],ctr,line[:-1]))\n",
    "                    if TF not in hasAlignedSeq:\n",
    "                        hasAlignedSeq.append(TF)\n",
    "                    ctr += 1\n",
    "\n",
    "# Get names of text files in patserIn/AlignedSeq (ONLY NEEDS TO BE DONE ONCE)\n",
    "_,_,filenames = next(os.walk('patserIn/AlignedSeq'),(None, None, []))\n",
    "TF_list = [x[:-4] for x in filenames if '.txt' in x]\n",
    "# Sanity Check: \n",
    "# [In]: set(hasAlignedSeq)-set(TF_list)\n",
    "# [Out]: set()\n",
    "\n",
    "# Sanity Check:\n",
    "# [In]: for TF in TF_list:\n",
    "#             with open('patserIn/AlignedSeq/%s.txt' %TF) as f:\n",
    "#                 nlines = sum([1 for line in f])\n",
    "#                 nalignseq = sum([1 for k in AlignedSeq if k.startswith(filteredPWMnames[TF])])\n",
    "#                 if nlines != nalignseq:\n",
    "#                     if nalignseq == 0:\n",
    "#                         if TF == 'dsx':\n",
    "#                             TF = 'dsx-F'\n",
    "#                         if nlines != len(od_AlignedSeq_FlyReg[TF]):\n",
    "#                             print '%s has %d aligned FlyReg sequences but %d sequences in the pasterIn/AlignedSeq file' %(TF,len(od_AlignedSeq_FlyReg[TF]),nlines)\n",
    "#                     else:\n",
    "#                         print '%s has %d aligned sequences but %d sequences in the pasterIn/AlignedSeq file' %(TF,nalignseq,nlines)\n",
    "# [Out]: \n",
    "\n",
    "# remove patserOut/AlignedSeq directory if it exists\n",
    "if os.path.exists('patserOut/AlignedSeq'):\n",
    "\tshutil.rmtree('patserOut/AlignedSeq')\n",
    "# create/recreate patserOut/AlignedSeq directory\n",
    "os.makedirs('patserOut/AlignedSeq')\n",
    "\n",
    "# Run patser using only the TF whose aligned binding sites are in that file\n",
    "path_to_patser = 'patser-v3e.1/patser-v3e'\n",
    "for tf in TF_list:\n",
    "    matrix = 'matrix/%s.txt' %tf # path to TF PWM file\n",
    "    inputFile = 'patserIn/AlignedSeq/%s.txt' %tf # input sequences\n",
    "    if not os.path.exists('patserOut/AlignedSeq'):\n",
    "        os.makedirs('patserOut/AlignedSeq')\n",
    "    outputFile = 'patserOut/AlignedSeq/AlignedSeq_%s.txt' %tf # PATSER output\n",
    "\n",
    "    cmd = [path_to_patser, '-A', 'a:t', '0.297', 'c:g', '0.203', \\\n",
    "           '-p', '-m', matrix, '-b', '0', '-d1', '-f', inputFile] \n",
    "\n",
    "    process = subprocess.call(cmd,stdout = open(outputFile, 'w'))\n",
    "    print('Done: %s' %tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlignedSeq_Aef1.txt\n"
     ]
    }
   ],
   "source": [
    "# NEEDS ONLY TO BE RUN ONCE\n",
    "## Make dictionaries ln(p-value) data and the number of aligned sequences\n",
    "_,_,filenames = next(os.walk('patserOut/AlignedSeq'),(None, None, []))\n",
    "lnp_data = {}\n",
    "nseq = collections.OrderedDict()\n",
    "regex_tf = re.compile('AlignedSeq_([\\w\\d\\-\\(\\)\\.]+).txt')\n",
    "\n",
    "if not os.path.exists('patserAnalysis'):\n",
    "    os.makedirs('patserAnalysis')\n",
    "\n",
    "# Write lnp distribution data to file in Modified folder\n",
    "with open('patserAnalysis/lnp_data.txt','w') as f1:\n",
    "    for file in filenames:\n",
    "        regex = re.compile('([\\w\\(\\)\\.-]+)_(\\d+)\\s+position=\\s+[\\dC]+\\s+score=\\s+[\\d\\.]+\\s+ln\\(p-value\\)=\\s+([\\-\\.\\w]+)')\n",
    "        # group(1) = gene name\n",
    "        # group(2) = gene name modifier\n",
    "        # group(3) = ln(p-value)\n",
    "        with open('patserOut/AlignedSeq/%s' %file,'r') as f:\n",
    "            temp = []\n",
    "            for line in f:\n",
    "                if regex.search(line):\n",
    "                    m = regex.search(line)\n",
    "                    if m:\n",
    "                        Key = m.group(1)\n",
    "                        # put ln(p-value) in temporary list\n",
    "                        temp.append(float(m.group(3)))\n",
    "            # append temporary list of ln(p-value)s to full list\n",
    "            if len(temp) > 0:\n",
    "                m = regex_tf.search(file)\n",
    "                lnp_data[m.group(1)] = temp\n",
    "                nseq[m.group(1)] = len(temp)\n",
    "                f1.write('>%s\\n%s\\n' %(m.group(1),str(temp)[1:-1]))\n",
    "            else:\n",
    "                print file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write PWMs to file\n",
    "with open('Datasets/Modified/PFMs.fasta','w') as f:\n",
    "    for TF in lnp_data.keys():\n",
    "        f.write('>%s\\n%s\\n' %(TF,\"\\n\".join(\" \".join(map(str, [int(item) for item in line])) for line in PWM[TF])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PWM for croc.\n",
      "No PWM for Stat92E.\n",
      "No PWM for tsh.\n",
      "No PWM for Dad.\n"
     ]
    }
   ],
   "source": [
    "# Read in the principal TFs involved in early embryogenesis/axis patterning\n",
    "axis_TFs = []\n",
    "with open('Datasets/AP_DV_TFs.txt','r') as f:\n",
    "    for line in f:\n",
    "        axis_TFs.append(line.split(','))\n",
    "axis_TFs[0][-1] = axis_TFs[0][-1].strip('[]')[:-1]\n",
    "\n",
    "for i in [0,1]:\n",
    "    remove = []\n",
    "    for tf in axis_TFs[i]:\n",
    "        if tf not in PWM.keys():\n",
    "            remove.append(tf)\n",
    "            print 'No PWM for %s.' %tf\n",
    "    for item in remove:\n",
    "        axis_TFs[i].remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write AP/DV TFs to file in Modified folder\n",
    "axis = ['AP','DV']\n",
    "with open('Datasets/Modified/AP_DV_TFs.txt','w') as f:\n",
    "    for i in range(2):\n",
    "        f.write('>%s\\n%s\\n' %(axis[i],','.join(map(str,axis_TFs[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[188, 216, 202, 219, 265, 276]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write TFs by Stage to file in Modified folder\n",
    "# Determine which TFs are expressed during which stage based on in situ data\n",
    "Stage = ['1_3','4_6','7_8','9_10','11_12','13_16']\n",
    "insitu = pd.read_csv('Datasets/insitu_annot.csv',names=['gene_symb','CG','FBgn','stage','staining'])\n",
    "insitu_ns = insitu[insitu.staining != 'no staining']\n",
    "TF_stage = {}\n",
    "FBgn_notfound = []\n",
    "with open('Datasets/Modified/TFs_by_stage.txt','w') as f:\n",
    "    for stage in insitu['stage'].unique():\n",
    "        temp_stage = Stage[stage-1]\n",
    "        TF_stage[temp_stage] = []\n",
    "        for FBgn in insitu_ns.FBgn[insitu_ns.stage == stage]:\n",
    "            try:\n",
    "                if (type(FBgn)==str) and ('FBgn' in FBgn) and (len(geneID[FBgn]) == 1):\n",
    "                    if (geneID[FBgn][0] in lnp_data.keys()) and not (geneID[FBgn][0] in TF_stage[temp_stage]):\n",
    "                        TF_stage[temp_stage].append(geneID[FBgn][0])\n",
    "            except KeyError:\n",
    "                if not (FBgn in FBgn_notfound):\n",
    "                    FBgn_notfound.append(FBgn)\n",
    "        TF_stage[temp_stage] = sorted(TF_stage[temp_stage],key=lambda t:t.lower())\n",
    "        f.write('>%s\\n%s\\n' %(temp_stage,','.join(map(str, TF_stage[temp_stage]))))\n",
    "[len(TF_stage[stage]) for stage in Stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VTID</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Refined element ID</th>\n",
       "      <th>Chromosome.1</th>\n",
       "      <th>Start.1</th>\n",
       "      <th>End.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VT0005</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>15507</td>\n",
       "      <td>17836</td>\n",
       "      <td>VT0005.1</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>15507</td>\n",
       "      <td>15809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VT0005</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>15507</td>\n",
       "      <td>17836</td>\n",
       "      <td>VT0005.2</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>16220</td>\n",
       "      <td>17836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VT0006</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>16836</td>\n",
       "      <td>18924</td>\n",
       "      <td>VT0006.1</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>16836</td>\n",
       "      <td>18924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VT0007</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>18031</td>\n",
       "      <td>20238</td>\n",
       "      <td>VT0007.1</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>18031</td>\n",
       "      <td>19325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VT0007</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>18031</td>\n",
       "      <td>20238</td>\n",
       "      <td>VT0007.2</td>\n",
       "      <td>chr2L</td>\n",
       "      <td>19695</td>\n",
       "      <td>19913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     VTID Chromosome  Start    End Refined element ID Chromosome.1  Start.1  \\\n",
       "0  VT0005      chr2L  15507  17836           VT0005.1        chr2L    15507   \n",
       "1  VT0005      chr2L  15507  17836           VT0005.2        chr2L    16220   \n",
       "2  VT0006      chr2L  16836  18924           VT0006.1        chr2L    16836   \n",
       "3  VT0007      chr2L  18031  20238           VT0007.1        chr2L    18031   \n",
       "4  VT0007      chr2L  18031  20238           VT0007.2        chr2L    19695   \n",
       "\n",
       "   End.1  \n",
       "0  15809  \n",
       "1  17836  \n",
       "2  18924  \n",
       "3  19325  \n",
       "4  19913  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing the minimal Vienna Tile enhancers\n",
    "# Read in the minimal VT enhancers\n",
    "VT_ALL = pd.read_csv('Datasets/2014-01-00083C-Supplementary Table 1.csv')\n",
    "minVT_ALL = pd.read_csv('Datasets/2014-01-00083C-Supplementary Table 3.csv')\n",
    "minVT_ALL.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3580"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep the VT enhancers that have been minimized, are positive and have been verified\n",
    "# Note: Positive  = at least one annotation term with strength > 1 \n",
    "#                   (excluding enhancers with only very weak (1) activities).\n",
    "# (Identity) Verified = confirmed using PCR of genomic DNA isolated from transgenic flies followed by Sanger sequencing \n",
    "#                       (includes 96% of the lines; the remaining 4% were either not tested or failed).\n",
    "ctr1 = 0\n",
    "with open('Datasets/Modified/VTminimizedOnly.bed','w') as f:\n",
    "    for index, row in minVT_ALL.iterrows():\n",
    "        if not (row.Start == row['Start.1'] and row.End == row['End.1']):\n",
    "            if (VT_ALL.Verification_status[VT_ALL.VTID == row['VTID']] == 'correct').bool():\n",
    "                if (VT_ALL.Positive[VT_ALL.VTID == row['VTID']] == 1).bool():\n",
    "                    ctr1 += 1\n",
    "                    f.write('%s\\t%s\\t%s\\t%s\\n' %(row['Chromosome.1'],row['Start.1'],row['End.1'],row['Refined element ID']))\n",
    "ctr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3580"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: go from VT to minimized VT\n",
    "ctr = 0\n",
    "for index, row in VT_ALL.iterrows():\n",
    "    if row.Positive == 1 and row.Verification_status == 'correct':\n",
    "        temp = minVT_ALL[minVT_ALL.VTID == row.VTID]\n",
    "        if temp.shape[0] > 1:\n",
    "            ctr += temp.shape[0]\n",
    "        if temp.shape[0] == 1:\n",
    "            if (temp.Start == temp['Start.1']).bool(): \n",
    "                if (temp.End != temp['End.1']).bool():\n",
    "                    ctr +=1\n",
    "            if (temp.End == temp['End.1']).bool():\n",
    "                if (temp.Start != temp['Start.1']).bool():\n",
    "                    ctr += 1\n",
    "            if (temp.Start != temp['Start.1']).bool():\n",
    "                if (temp.End != temp['End.1']).bool():\n",
    "                    ctr += 1\n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No coordinates unlifted.\n"
     ]
    }
   ],
   "source": [
    "# Liftover from dm3 to dm6\n",
    "# ./liftOver Datasets/Modified/VTminimizedOnly.bed Datasets/dm3ToDm6.over.chain.gz Datasets/Modified/VTminimizedOnly_dm6.bed Datasets/Modified/VTminimizedOnly_unlifted.bed\n",
    "\n",
    "# Liftover from dm3 to dm6\n",
    "command =['./liftOver', \\\n",
    "          'Datasets/Modified/VTminimizedOnly.bed', \\\n",
    "          'Datasets/dm3ToDm6.over.chain.gz', \\\n",
    "          'Datasets/Modified/VTminimizedOnly_dm6.bed', \\\n",
    "          'Datasets/Modified/VTminimizedOnly_unlifted.bed']\n",
    "process = subprocess.call(command)\n",
    "# Sanity check: no coordinates unlifted\n",
    "if os.stat('Datasets/Modified/VTminimizedOnly_unlifted.bed').st_size==0:\n",
    "    print 'No coordinates unlifted.'\n",
    "else:\n",
    "    print 'Some coordinates unlifted!'\n",
    "\n",
    "# Pick out the sequences from dm6\n",
    "dm6 = readFASTA('Datasets/dm6.fa','sequences',0,geneID,0,0)\n",
    "with open('Datasets/Modified/VTminimizedOnly_dm6.fa','w') as f1:\n",
    "    with open('Datasets/Modified/VTminimizedOnly_dm6.bed','r') as f:\n",
    "        for line in f:\n",
    "            temp = line[:-1].split('\\t')\n",
    "            f1.write('>%s\\n%s\\n' %(temp[3], dm6[temp[0]][int(temp[1])-1:int(temp[2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort VT enhancers by stage in which they are expressed\n",
    "minVT_enhancers_ALL = readFASTA('Datasets/Modified/VTminimizedOnly_dm6.fa','sequences',0,geneID,0)\n",
    "minVT_enhancers = [] # initialize list of lists of minimized VT enhancers by stage\n",
    "for stage in ['4_6','7_8','9_10','11_12','13_14','15_16']:\n",
    "    temp = {k:v for k,v in minVT_enhancers_ALL.iteritems() for vt in VT_ALL.VTID[pd.notnull(VT_ALL['stg%s' %stage])] if vt in k}\n",
    "    if stage == '15_16': # combine stages 13-14 and 15-16 to match with in situ staging\n",
    "        minVT_enhancers[-1].update(temp) # merges active enhancers in stages 13-14 and 15-16\n",
    "    else:\n",
    "        minVT_enhancers.append(temp)\n",
    "\n",
    "Stage = ['4_6','7_8','9_10','11_12','13_16']\n",
    "with open('Datasets/Modified/VTminimizedbyStage.txt', 'w') as f:\n",
    "    for i in range(len(minVT_enhancers)):\n",
    "        f.write('>%s\\n%s\\n' %(Stage[i],','.join(minVT_enhancers[i].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define heterodimers and write to file in Modified folder\n",
    "# Heterodimers with da\n",
    "forward = {}\n",
    "forward[0] = ['ase','Fer3','Hand','nau']\n",
    "forward[-1] = ['ac','ato','CG33557','Fer2','l(1)sc','sc']\n",
    "forward[-2] = ['amos','cato','da','Fer1','HLH54F','net','twi','tx']\n",
    "forward[-3] = ['dimm','Oli']\n",
    "forward[-4] = ['sage','tap']\n",
    "forward[-5] = ['HLH4C']\n",
    "\n",
    "pair1 = ['Mondo','bigmax','Jra','kay','CG6272','Xrp1','crc','Max','Myc','Mnt','tai','Clk','cyc','gce','tgo','dysf','sima','sim','ss']\n",
    "pair2 = ['bigmax','Mondo','kay','Jra','Xrp1','CG6272','CG6272','Myc','Max','Max','Clk','tai','Clk','Clk','dysf','tgo','tgo','tgo','tgo']\n",
    "heterodimers = dict(zip(pair1,pair2))\n",
    "for k in [subitem for item in forward.values() for subitem in item]:\n",
    "    heterodimers[k] = 'da'\n",
    "\n",
    "with open('Datasets/Modified/heterodimers.txt','w') as f:\n",
    "    for k,v in heterodimers.iteritems():\n",
    "        f.write('>%s\\n%s\\n' %(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Look at overlap between axis patterning and the minimal Vienna Tile enhancers\n",
    "# Write D. mel AP/DV enhancers to fasta files (input for blat to determine genomic coordinates of enhancers)\n",
    "AP_enhancers = readFASTA('Datasets/ap_enc_12.fa','sequences',0,geneID,re.compile('([\\w\\-]+)_mel'))\n",
    "DV_enhancers = readFASTA('Datasets/dv_enc_12.fa','sequences',0,geneID,re.compile('([\\w\\-]+)_mel'))\n",
    "\n",
    "with open('Datasets/Modified/AP_enhancers_mel.fa', 'w') as f:\n",
    "    for k,v in AP_enhancers.iteritems():\n",
    "        f.write('>%s\\n%s\\n' %(k,v))\n",
    "with open('Datasets/Modified/DV_enhancers_mel.fa', 'w') as f:\n",
    "    for k,v in DV_enhancers.iteritems():\n",
    "        f.write('>%s\\n%s\\n' %(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run AP/DV enhancers through Blat to determine their genomic coordinates\n",
    "\n",
    "#./blat Datasets/dm6.fa Datasets/Modified/AP_enhancers_mel.fa AP_enhancers_mel_coord.psl\n",
    "\n",
    "command = []\n",
    "command.append(['./blat', \\\n",
    "                'Datasets/dm3.2bit', \\\n",
    "                'Datasets/Modified/AP_enhancers_mel.fa', \\\n",
    "                'Datasets/Modified/AP_enhancers_mel_coord.psl'])\n",
    "command.append(['./blat', \\\n",
    "                'Datasets/dm3.2bit', \\\n",
    "                'Datasets/Modified/DV_enhancers_mel.fa', \\\n",
    "                'Datasets/Modified/DV_enhancers_mel_coord.psl'])\n",
    "for cmd in command:\n",
    "    process = subprocess.call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mes5 has a match distance of -1\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('(\\d+)\\t\\d+\\t\\d+\\t\\d+\\t\\d+\\t\\d+\\t\\d+\\t\\d+\\t[\\+\\-]\\t([\\w\\d\\-]+)\\t(\\d+)\\t\\d+\\t\\d+\\t(chr[\\d\\w]+)\\t\\d+\\t(\\d+)\\t(\\d+)')\n",
    "\n",
    "for axis in ['AP','DV']:\n",
    "    coordinates = {}\n",
    "    match_distance = {}\n",
    "    with open('Datasets/Modified/%s_enhancers_mel_coord.bed' %axis,'w') as f:\n",
    "        with open('Datasets/Modified/%s_enhancers_mel_coord.psl' %axis,'r') as f1:\n",
    "            for line in f1:\n",
    "                m = regex.search(line)\n",
    "                # group(1) = match length\n",
    "                # group(2) = enhancer name\n",
    "                # group(3) = query length\n",
    "                # group(4) = chromosome\n",
    "                # group(5) = start\n",
    "                # group(6) = end\n",
    "                if m:\n",
    "                    if m.group(2) not in match_distance.keys() or \\\n",
    "                    m.group(2) in match_distance.keys() and int(m.group(1)) - int(m.group(3)) > match_distance[m.group(2)]:\n",
    "                            match_distance[m.group(2)] = int(m.group(1)) - int(m.group(3))\n",
    "                            coordinates[m.group(2)] = '%s\\t%s\\t%s\\t%s\\n' %(m.group(4),m.group(5),m.group(6),m.group(2))\n",
    "        for k,v in coordinates.iteritems():\n",
    "            f.write(v)\n",
    "            if match_distance[k] != 0:\n",
    "                print '%s has a match distance of %d' %(k,match_distance[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No coordinates unlifted.\n",
      "No coordinates unlifted.\n"
     ]
    }
   ],
   "source": [
    "# Liftover from dm3 to dm6\n",
    "for axis in ['AP','DV']:\n",
    "    command =['./liftOver', \\\n",
    "              'Datasets/Modified/%s_enhancers_mel_coord.bed' %axis, \\\n",
    "              'Datasets/dm3ToDm6.over.chain.gz', \\\n",
    "              'Datasets/Modified/%s_enhancers_mel_coord_dm6.bed' %axis, \\\n",
    "              'Datasets/Modified/%s_enhancers_mel_coord_unlifted.bed' %axis]\n",
    "    process = subprocess.call(command)\n",
    "    # Sanity check: no coordinates unlifted\n",
    "    if os.stat('Datasets/Modified/VTminimizedOnly_unlifted.bed').st_size==0:\n",
    "        print 'No coordinates unlifted.'\n",
    "    else:\n",
    "        print 'Some coordinates unlifted!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_enh_pat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>enhancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>18031</td>\n",
       "      <td>19325</td>\n",
       "      <td>VT0007.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>19695</td>\n",
       "      <td>19913</td>\n",
       "      <td>VT0007.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>54362</td>\n",
       "      <td>54503</td>\n",
       "      <td>VT0025.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>55162</td>\n",
       "      <td>55359</td>\n",
       "      <td>VT0025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>243746</td>\n",
       "      <td>243866</td>\n",
       "      <td>VT0108.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     chr   start     end  enhancer\n",
       "0  chr2L   18031   19325  VT0007.1\n",
       "1  chr2L   19695   19913  VT0007.2\n",
       "2  chr2L   54362   54503  VT0025.1\n",
       "3  chr2L   55162   55359  VT0025.2\n",
       "4  chr2L  243746  243866  VT0108.1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Look at the overlap between the AP/DV and the minimal VT enhancers\n",
    "# Read in the coordinates for the AP enhancers\n",
    "ap_enh_pat = pd.read_csv('Datasets/Modified/AP_enhancers_mel_coord_dm6.bed',sep = '\\t',header=None)\n",
    "ap_enh_pat.columns = ['chr','start','end','enhancer']\n",
    "ap_enh_pat[['start','end']] = ap_enh_pat[['start','end']].astype(int)\n",
    "ap_enh_pat = ap_enh_pat.sort_values('enhancer') # alphabetize by enhancer name\n",
    "# Read in the coordinates for the DV enhancers\n",
    "dv_enh_pat = pd.read_csv('Datasets/Modified/DV_enhancers_mel_coord_dm6.bed',sep = '\\t',header=None)\n",
    "dv_enh_pat.columns = ['chr','start','end','enhancer']\n",
    "dv_enh_pat[['start','end']] = dv_enh_pat[['start','end']].astype(int)\n",
    "dv_enh_pat = dv_enh_pat.sort_values('enhancer') # alphabetize by enhancer name\n",
    "# Read in the coordinates for the minimized VT enhancers\n",
    "minVT_enh = pd.read_csv('Datasets/Modified/VTminimizedOnly_dm6.bed',sep = '\\t',header=None)\n",
    "minVT_enh.columns = ['chr','start','end','enhancer']\n",
    "minVT_enh[['start','end']] = minVT_enh[['start','end']].astype(int)\n",
    "minVT_enh = minVT_enh.sort_values('enhancer') # alphabetize by enhancer name\n",
    "minVT_enh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Papatsenko</th>\n",
       "      <th>Stark</th>\n",
       "      <th>Percent_Overlap</th>\n",
       "      <th>Stage4_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ems-up</td>\n",
       "      <td>VT41284.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eve-15</td>\n",
       "      <td>VT14368.1</td>\n",
       "      <td>70.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eve-37</td>\n",
       "      <td>VT14361.2</td>\n",
       "      <td>78.7</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eve-37</td>\n",
       "      <td>VT14362.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eve-46</td>\n",
       "      <td>VT14366.1</td>\n",
       "      <td>74.3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eve-46</td>\n",
       "      <td>VT14367.1</td>\n",
       "      <td>93.9</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eve-M</td>\n",
       "      <td>VT14367.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eve-M</td>\n",
       "      <td>VT14367.3</td>\n",
       "      <td>39.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eve-M</td>\n",
       "      <td>VT14368.1</td>\n",
       "      <td>55.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ftz-15</td>\n",
       "      <td>VT37571.1</td>\n",
       "      <td>43.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ftz-up</td>\n",
       "      <td>VT37567.1</td>\n",
       "      <td>44.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ftz-up</td>\n",
       "      <td>VT37567.2</td>\n",
       "      <td>29.3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gt-1</td>\n",
       "      <td>VT55795.2</td>\n",
       "      <td>75.5</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gt-23</td>\n",
       "      <td>VT55793.1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gt-P</td>\n",
       "      <td>VT55790.2</td>\n",
       "      <td>78.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gt-P</td>\n",
       "      <td>VT55791.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gt-minus1</td>\n",
       "      <td>VT55790.1</td>\n",
       "      <td>24.7</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gt-minus1</td>\n",
       "      <td>VT55790.2</td>\n",
       "      <td>26.3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>h-15</td>\n",
       "      <td>VT27680.1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>h-15</td>\n",
       "      <td>VT27680.2</td>\n",
       "      <td>27.8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h-267</td>\n",
       "      <td>VT27677.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>h-267</td>\n",
       "      <td>VT27678.1</td>\n",
       "      <td>55.1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>h-267</td>\n",
       "      <td>VT27679.1</td>\n",
       "      <td>30.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>h-34</td>\n",
       "      <td>VT27677.1</td>\n",
       "      <td>90.8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kni-cis</td>\n",
       "      <td>VT33934.2</td>\n",
       "      <td>79.7</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kni-cis</td>\n",
       "      <td>VT33935.1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kni-minus5</td>\n",
       "      <td>VT33936.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kni-plus1</td>\n",
       "      <td>VT33934.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kr-CD1</td>\n",
       "      <td>VT22278.2</td>\n",
       "      <td>24.9</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nub-blst</td>\n",
       "      <td>VT6449.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nub-blst</td>\n",
       "      <td>VT6450.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nub-plus5</td>\n",
       "      <td>VT6454.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nub-plus5</td>\n",
       "      <td>VT6455.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>otd-E</td>\n",
       "      <td>VT58873.1</td>\n",
       "      <td>52.1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>otd-E</td>\n",
       "      <td>VT58874.1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>pdm2-plus1</td>\n",
       "      <td>VT6482.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pdm2-plus1</td>\n",
       "      <td>VT6483.1</td>\n",
       "      <td>71.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pdm2-plus1</td>\n",
       "      <td>VT6483.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pdm2-plus3</td>\n",
       "      <td>VT6483.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pdm2-plus3</td>\n",
       "      <td>VT6484.1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pdm2-plus3</td>\n",
       "      <td>VT6484.2</td>\n",
       "      <td>60.5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>prd-1</td>\n",
       "      <td>VT6169.2</td>\n",
       "      <td>64.7</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>prd-1</td>\n",
       "      <td>VT6169.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>prd-1</td>\n",
       "      <td>VT6170.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>prd-1</td>\n",
       "      <td>VT6170.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>prd-P</td>\n",
       "      <td>VT6169.1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>prd-P</td>\n",
       "      <td>VT6169.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>prd-P2</td>\n",
       "      <td>VT6170.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>prd-plus6</td>\n",
       "      <td>VT6164.2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>prd-plus6</td>\n",
       "      <td>VT6165.1</td>\n",
       "      <td>53.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>prd-plus6</td>\n",
       "      <td>VT6165.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>slp-B</td>\n",
       "      <td>VT1970.1</td>\n",
       "      <td>11.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>slp-B</td>\n",
       "      <td>VT1970.2</td>\n",
       "      <td>27.9</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>slp-B</td>\n",
       "      <td>VT1971.1</td>\n",
       "      <td>11.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>slp-B</td>\n",
       "      <td>VT1971.2</td>\n",
       "      <td>75.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>slp-ecto</td>\n",
       "      <td>VT1966.2</td>\n",
       "      <td>40.5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>slp-ecto</td>\n",
       "      <td>VT1967.1</td>\n",
       "      <td>85.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>slp1-head</td>\n",
       "      <td>VT1967.2</td>\n",
       "      <td>72.5</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>slp2-minus3</td>\n",
       "      <td>VT1973.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tll-plus4</td>\n",
       "      <td>VT50157.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tll-plus4</td>\n",
       "      <td>VT50159.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>brk</td>\n",
       "      <td>VT58195.3</td>\n",
       "      <td>30.3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>eve-M</td>\n",
       "      <td>VT14367.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>eve-M</td>\n",
       "      <td>VT14367.3</td>\n",
       "      <td>39.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>eve-M</td>\n",
       "      <td>VT14368.1</td>\n",
       "      <td>55.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>hnt</td>\n",
       "      <td>VT56875.1</td>\n",
       "      <td>40.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>hnt</td>\n",
       "      <td>VT56876.1</td>\n",
       "      <td>35.5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mes3</td>\n",
       "      <td>VT28266.1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pnr</td>\n",
       "      <td>VT42370.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>rho</td>\n",
       "      <td>VT24024.2</td>\n",
       "      <td>28.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>rho</td>\n",
       "      <td>VT24025.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>sna</td>\n",
       "      <td>VT7920.1</td>\n",
       "      <td>43.9</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tld</td>\n",
       "      <td>VT46946.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tup</td>\n",
       "      <td>VT9666.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>vnd</td>\n",
       "      <td>VT54910.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>vnd-M</td>\n",
       "      <td>VT54907.1</td>\n",
       "      <td>36.3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>vnd-M</td>\n",
       "      <td>VT54907.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>vnd-V</td>\n",
       "      <td>VT54905.1</td>\n",
       "      <td>42.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>zen</td>\n",
       "      <td>VT37509.2</td>\n",
       "      <td>79.5</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Papatsenko      Stark Percent_Overlap Stage4_6\n",
       "1        ems-up  VT41284.1            15.8      yes\n",
       "2        eve-15  VT14368.1            70.6      yes\n",
       "3        eve-37  VT14361.2            78.7      yes\n",
       "4        eve-37  VT14362.1           100.0      yes\n",
       "5        eve-46  VT14366.1            74.3      yes\n",
       "6        eve-46  VT14367.1            93.9      yes\n",
       "7         eve-M  VT14367.2            13.8      yes\n",
       "8         eve-M  VT14367.3            39.2      yes\n",
       "9         eve-M  VT14368.1            55.6      yes\n",
       "10       ftz-15  VT37571.1            43.2      yes\n",
       "11       ftz-up  VT37567.1            44.4      yes\n",
       "12       ftz-up  VT37567.2            29.3      yes\n",
       "13         gt-1  VT55795.2            75.5      yes\n",
       "14        gt-23  VT55793.1            25.3      yes\n",
       "15         gt-P  VT55790.2            78.4      yes\n",
       "16         gt-P  VT55791.1            74.6      yes\n",
       "17    gt-minus1  VT55790.1            24.7      yes\n",
       "18    gt-minus1  VT55790.2            26.3      yes\n",
       "19         h-15  VT27680.1            19.9      yes\n",
       "20         h-15  VT27680.2            27.8      yes\n",
       "21        h-267  VT27677.1             3.9      yes\n",
       "22        h-267  VT27678.1            55.1      yes\n",
       "23        h-267  VT27679.1            30.4      yes\n",
       "24         h-34  VT27677.1            90.8      yes\n",
       "25      kni-cis  VT33934.2            79.7      yes\n",
       "26      kni-cis  VT33935.1            29.1      yes\n",
       "27   kni-minus5  VT33936.1            31.9      yes\n",
       "28    kni-plus1  VT33934.1             7.6      yes\n",
       "29       kr-CD1  VT22278.2            24.9      yes\n",
       "30     nub-blst   VT6449.2            18.2      yes\n",
       "31     nub-blst   VT6450.1            75.0      yes\n",
       "32    nub-plus5   VT6454.2             9.1       no\n",
       "33    nub-plus5   VT6455.1             9.1       no\n",
       "34        otd-E  VT58873.1            52.1      yes\n",
       "35        otd-E  VT58874.1            63.1      yes\n",
       "36   pdm2-plus1   VT6482.1            20.9       no\n",
       "37   pdm2-plus1   VT6483.1            71.4      yes\n",
       "38   pdm2-plus1   VT6483.2             8.4      yes\n",
       "39   pdm2-plus3   VT6483.2             8.3      yes\n",
       "40   pdm2-plus3   VT6484.1            34.6       no\n",
       "41   pdm2-plus3   VT6484.2            60.5       no\n",
       "42        prd-1   VT6169.2            64.7      yes\n",
       "43        prd-1   VT6169.3            11.0      yes\n",
       "44        prd-1   VT6170.1            18.1       no\n",
       "45        prd-1   VT6170.2            11.0       no\n",
       "46        prd-P   VT6169.1             9.4      yes\n",
       "47        prd-P   VT6169.2            13.6      yes\n",
       "48       prd-P2   VT6170.3             0.3       no\n",
       "49    prd-plus6   VT6164.2            28.5      yes\n",
       "50    prd-plus6   VT6165.1            53.4      yes\n",
       "51    prd-plus6   VT6165.2            11.6      yes\n",
       "52        slp-B   VT1970.1            11.2      yes\n",
       "53        slp-B   VT1970.2            27.9      yes\n",
       "54        slp-B   VT1971.1            11.2      yes\n",
       "55        slp-B   VT1971.2            75.2      yes\n",
       "56     slp-ecto   VT1966.2            40.5       no\n",
       "57     slp-ecto   VT1967.1            85.6      yes\n",
       "58    slp1-head   VT1967.2            72.5      yes\n",
       "59  slp2-minus3   VT1973.3            11.4       no\n",
       "60    tll-plus4  VT50157.2            14.4      yes\n",
       "61    tll-plus4  VT50159.1            11.6       no\n",
       "62          brk  VT58195.3            30.3       no\n",
       "63        eve-M  VT14367.2            13.8      yes\n",
       "64        eve-M  VT14367.3            39.2      yes\n",
       "65        eve-M  VT14368.1            55.6      yes\n",
       "66          hnt  VT56875.1            40.6      yes\n",
       "67          hnt  VT56876.1            35.5       no\n",
       "68         mes3  VT28266.1            62.0      yes\n",
       "69          pnr  VT42370.1           100.0       no\n",
       "70          rho  VT24024.2            28.1       no\n",
       "71          rho  VT24025.1           100.0       no\n",
       "72          sna   VT7920.1            43.9       no\n",
       "73          tld  VT46946.1            97.0      yes\n",
       "74          tup   VT9666.2           100.0      yes\n",
       "75          vnd  VT54910.1           100.0      yes\n",
       "76        vnd-M  VT54907.1            36.3      yes\n",
       "77        vnd-M  VT54907.2            12.2      yes\n",
       "78        vnd-V  VT54905.1            42.2      yes\n",
       "79          zen  VT37509.2            79.5      yes"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table S2: Overlap between axis patterning and the minimal Vienna Tile enhancers\n",
    "columns = ['Papatsenko', 'Stark', 'Percent_Overlap', 'Stage4_6']\n",
    "matches = pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns) \n",
    "i = 0\n",
    "for index,row in ap_enh_pat.iterrows():\n",
    "    for index1,row1 in minVT_enh[minVT_enh.chr == row.chr].iterrows():\n",
    "        if len(set(range(row.start,row.end)).intersection(range(row1.start,row1.end))) > 0:\n",
    "            i += 1\n",
    "            match_len = 100*float(len(set(range(row.start,row.end)).intersection(range(row1.start,row1.end))))/len(range(row.start,row.end))\n",
    "            match_stage = (row1.enhancer in minVT_enhancers[0])\n",
    "            matches.loc[i] = [row.enhancer, row1.enhancer, '%.1f' %match_len, '%s' %['yes' if int(match_stage) else 'no'][0]]\n",
    "for index,row in dv_enh_pat.iterrows():\n",
    "    for index1,row1 in minVT_enh[minVT_enh.chr == row.chr].iterrows():\n",
    "        if len(set(range(row.start,row.end)).intersection(range(row1.start,row1.end))) > 0:\n",
    "            i += 1\n",
    "            match_len = 100*float(len(set(range(row.start,row.end)).intersection(range(row1.start,row1.end))))/len(range(row.start,row.end))\n",
    "            match_stage = (row1.enhancer in minVT_enhancers[0])\n",
    "            matches.loc[i] = [row.enhancer, row1.enhancer, '%.1f' %match_len, '%s' %['yes' if int(match_stage) else 'no'][0]]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches.to_csv('Datasets/Modified/Dataset_Overlap.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
